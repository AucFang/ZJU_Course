{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FruitToEmoji-GIT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92-4Hjy7kA8"
      },
      "source": [
        "<a href=\"https://www.arduino.cc/\"><img src=\"https://raw.githubusercontent.com/sandeepmistry/aimldevfest-workshop-2019/master/images/Arduino_logo_R_highquality.png\" width=200/></a>\n",
        "# Tiny ML on Arduino\n",
        "## Classify objects by color tutorial\n",
        "\n",
        " \n",
        "https://github.com/arduino/ArduinoTensorFlowLiteTutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Setup Python Environment \n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63dae1fd-c875-4138-d517-5571b743fb5c"
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.49.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the Files tab\n",
        "1. Drag `csv` files from your computer to the tab to upload them into colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the full connected neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "b5c4c2c0-139a-4767-d989-0213e2f8417a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import fileinput\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "CLASSES = [];\n",
        "\n",
        "for file in os.listdir(\"/content/\"):\n",
        "    if file.endswith(\".csv\"):\n",
        "        CLASSES.append(os.path.splitext(file)[0])\n",
        "\n",
        "CLASSES.sort()\n",
        "\n",
        "SAMPLES_WINDOW_LEN = 1\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for class_index in range(NUM_CLASSES):\n",
        "  objectClass = CLASSES[class_index]\n",
        "  df = pd.read_csv(\"/content/\" + objectClass + \".csv\")\n",
        "  columns = list(df)\n",
        "  # get rid of pesky empty value lines of csv which cause NaN inputs to TensorFlow\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop=True)\n",
        "   \n",
        "  # calculate the number of objectClass recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_WINDOW_LEN)\n",
        "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
        "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
        "\n",
        "  # graphing\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,1)\n",
        "  pixels = np.array([df['Red'],df['Green'],df['Blue']],float)\n",
        "  pixels = np.transpose(pixels)\n",
        "  for i in range(num_recordings):\n",
        "    plt.axvline(x=i, linewidth=8, color=tuple(pixels[i]/np.max(pixels[i], axis=0)))\n",
        "  plt.show()\n",
        "  \n",
        "  #tensors\n",
        "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    row = []\n",
        "    for c in columns:\n",
        "      row.append(df[c][i])\n",
        "    tensor += row\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version = 2.9.2\n",
            "\n",
            "\u001b[32;4mgreen\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
            "281 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;4mpink\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
            "129 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;4myellow\u001b[0m class will be output \u001b[32m2\u001b[0m of the classifier\n",
            "258 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set parsing and preparation complete.\n",
            "Data set randomization and splitting complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8qlSAX1b6Yv"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00617c8d-7f06-4c8f-d10f-2084096f9a8b"
      },
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=400, batch_size=4, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "100/100 [==============================] - 1s 4ms/step - loss: 0.2110 - mae: 0.4328 - val_loss: 0.2030 - val_mae: 0.4244\n",
            "Epoch 2/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1929 - mae: 0.4131 - val_loss: 0.1849 - val_mae: 0.4034\n",
            "Epoch 3/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1709 - mae: 0.3858 - val_loss: 0.1628 - val_mae: 0.3744\n",
            "Epoch 4/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1484 - mae: 0.3532 - val_loss: 0.1430 - val_mae: 0.3431\n",
            "Epoch 5/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1290 - mae: 0.3189 - val_loss: 0.1265 - val_mae: 0.3116\n",
            "Epoch 6/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1140 - mae: 0.2876 - val_loss: 0.1139 - val_mae: 0.2835\n",
            "Epoch 7/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1035 - mae: 0.2605 - val_loss: 0.1059 - val_mae: 0.2613\n",
            "Epoch 8/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0967 - mae: 0.2391 - val_loss: 0.1009 - val_mae: 0.2426\n",
            "Epoch 9/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.2238 - val_loss: 0.0974 - val_mae: 0.2323\n",
            "Epoch 10/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0895 - mae: 0.2148 - val_loss: 0.0945 - val_mae: 0.2213\n",
            "Epoch 11/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0870 - mae: 0.2055 - val_loss: 0.0924 - val_mae: 0.2150\n",
            "Epoch 12/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0851 - mae: 0.1989 - val_loss: 0.0903 - val_mae: 0.2090\n",
            "Epoch 13/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0828 - mae: 0.1936 - val_loss: 0.0882 - val_mae: 0.2043\n",
            "Epoch 14/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0803 - mae: 0.1878 - val_loss: 0.0850 - val_mae: 0.2011\n",
            "Epoch 15/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0769 - mae: 0.1837 - val_loss: 0.0815 - val_mae: 0.1960\n",
            "Epoch 16/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0734 - mae: 0.1787 - val_loss: 0.0783 - val_mae: 0.1911\n",
            "Epoch 17/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0698 - mae: 0.1739 - val_loss: 0.0744 - val_mae: 0.1848\n",
            "Epoch 18/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0655 - mae: 0.1670 - val_loss: 0.0700 - val_mae: 0.1794\n",
            "Epoch 19/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0612 - mae: 0.1622 - val_loss: 0.0654 - val_mae: 0.1730\n",
            "Epoch 20/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0565 - mae: 0.1554 - val_loss: 0.0605 - val_mae: 0.1671\n",
            "Epoch 21/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0513 - mae: 0.1493 - val_loss: 0.0560 - val_mae: 0.1574\n",
            "Epoch 22/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0462 - mae: 0.1404 - val_loss: 0.0496 - val_mae: 0.1491\n",
            "Epoch 23/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0403 - mae: 0.1315 - val_loss: 0.0432 - val_mae: 0.1398\n",
            "Epoch 24/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0335 - mae: 0.1204 - val_loss: 0.0363 - val_mae: 0.1291\n",
            "Epoch 25/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0278 - mae: 0.1104 - val_loss: 0.0309 - val_mae: 0.1180\n",
            "Epoch 26/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0229 - mae: 0.1004 - val_loss: 0.0258 - val_mae: 0.1083\n",
            "Epoch 27/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0189 - mae: 0.0909 - val_loss: 0.0217 - val_mae: 0.0993\n",
            "Epoch 28/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0825 - val_loss: 0.0182 - val_mae: 0.0893\n",
            "Epoch 29/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0739 - val_loss: 0.0152 - val_mae: 0.0805\n",
            "Epoch 30/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0662 - val_loss: 0.0133 - val_mae: 0.0721\n",
            "Epoch 31/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0597 - val_loss: 0.0109 - val_mae: 0.0665\n",
            "Epoch 32/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0539 - val_loss: 0.0092 - val_mae: 0.0612\n",
            "Epoch 33/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0494 - val_loss: 0.0087 - val_mae: 0.0554\n",
            "Epoch 34/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0449 - val_loss: 0.0081 - val_mae: 0.0499\n",
            "Epoch 35/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0406 - val_loss: 0.0066 - val_mae: 0.0464\n",
            "Epoch 36/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0367 - val_loss: 0.0059 - val_mae: 0.0440\n",
            "Epoch 37/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0349 - val_loss: 0.0063 - val_mae: 0.0390\n",
            "Epoch 38/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0306 - val_loss: 0.0049 - val_mae: 0.0380\n",
            "Epoch 39/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0292 - val_loss: 0.0047 - val_mae: 0.0345\n",
            "Epoch 40/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0271 - val_loss: 0.0040 - val_mae: 0.0328\n",
            "Epoch 41/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0320\n",
            "Epoch 42/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0244 - val_loss: 0.0040 - val_mae: 0.0285\n",
            "Epoch 43/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0226 - val_loss: 0.0034 - val_mae: 0.0289\n",
            "Epoch 44/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0222 - val_loss: 0.0033 - val_mae: 0.0261\n",
            "Epoch 45/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0210 - val_loss: 0.0031 - val_mae: 0.0250\n",
            "Epoch 46/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0196 - val_loss: 0.0032 - val_mae: 0.0235\n",
            "Epoch 47/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0188 - val_loss: 0.0030 - val_mae: 0.0225\n",
            "Epoch 48/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0179 - val_loss: 0.0029 - val_mae: 0.0214\n",
            "Epoch 49/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0165 - val_loss: 0.0025 - val_mae: 0.0212\n",
            "Epoch 50/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 0.0021 - val_mae: 0.0209\n",
            "Epoch 51/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 0.0027 - val_mae: 0.0189\n",
            "Epoch 52/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0144 - val_loss: 0.0023 - val_mae: 0.0183\n",
            "Epoch 53/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0138 - val_loss: 0.0025 - val_mae: 0.0175\n",
            "Epoch 54/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0132 - val_loss: 0.0020 - val_mae: 0.0173\n",
            "Epoch 55/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0127 - val_loss: 0.0024 - val_mae: 0.0163\n",
            "Epoch 56/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.3402e-04 - mae: 0.0121 - val_loss: 0.0017 - val_mae: 0.0169\n",
            "Epoch 57/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.4584e-04 - mae: 0.0125 - val_loss: 0.0017 - val_mae: 0.0158\n",
            "Epoch 58/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.8627e-04 - mae: 0.0120 - val_loss: 0.0016 - val_mae: 0.0153\n",
            "Epoch 59/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.3687e-04 - mae: 0.0109 - val_loss: 0.0016 - val_mae: 0.0148\n",
            "Epoch 60/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.9580e-04 - mae: 0.0112 - val_loss: 0.0017 - val_mae: 0.0139\n",
            "Epoch 61/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.2315e-04 - mae: 0.0104 - val_loss: 0.0019 - val_mae: 0.0132\n",
            "Epoch 62/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.9654e-04 - mae: 0.0102 - val_loss: 0.0017 - val_mae: 0.0130\n",
            "Epoch 63/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.0041e-04 - mae: 0.0096 - val_loss: 0.0015 - val_mae: 0.0128\n",
            "Epoch 64/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.9156e-04 - mae: 0.0094 - val_loss: 0.0015 - val_mae: 0.0121\n",
            "Epoch 65/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.5220e-04 - mae: 0.0094 - val_loss: 0.0016 - val_mae: 0.0117\n",
            "Epoch 66/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.5083e-04 - mae: 0.0089 - val_loss: 0.0012 - val_mae: 0.0120\n",
            "Epoch 67/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.5186e-04 - mae: 0.0085 - val_loss: 0.0019 - val_mae: 0.0109\n",
            "Epoch 68/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.4346e-04 - mae: 0.0083 - val_loss: 0.0014 - val_mae: 0.0108\n",
            "Epoch 69/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.8854e-04 - mae: 0.0079 - val_loss: 0.0011 - val_mae: 0.0111\n",
            "Epoch 70/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.6115e-04 - mae: 0.0081 - val_loss: 0.0021 - val_mae: 0.0101\n",
            "Epoch 71/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.6836e-04 - mae: 0.0071 - val_loss: 0.0015 - val_mae: 0.0099\n",
            "Epoch 72/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.4380e-04 - mae: 0.0071 - val_loss: 0.0012 - val_mae: 0.0099\n",
            "Epoch 73/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.9709e-04 - mae: 0.0072 - val_loss: 0.0017 - val_mae: 0.0093\n",
            "Epoch 74/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.8291e-04 - mae: 0.0066 - val_loss: 0.0020 - val_mae: 0.0091\n",
            "Epoch 75/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.9849e-04 - mae: 0.0065 - val_loss: 0.0014 - val_mae: 0.0090\n",
            "Epoch 76/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.1378e-04 - mae: 0.0062 - val_loss: 9.3022e-04 - val_mae: 0.0094\n",
            "Epoch 77/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.7009e-04 - mae: 0.0067 - val_loss: 0.0014 - val_mae: 0.0085\n",
            "Epoch 78/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.6445e-04 - mae: 0.0059 - val_loss: 0.0010 - val_mae: 0.0086\n",
            "Epoch 79/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.6313e-04 - mae: 0.0060 - val_loss: 0.0017 - val_mae: 0.0081\n",
            "Epoch 80/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.3841e-04 - mae: 0.0057 - val_loss: 9.9324e-04 - val_mae: 0.0082\n",
            "Epoch 81/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.9652e-04 - mae: 0.0058 - val_loss: 0.0013 - val_mae: 0.0077\n",
            "Epoch 82/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.4733e-04 - mae: 0.0057 - val_loss: 0.0011 - val_mae: 0.0077\n",
            "Epoch 83/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.3060e-04 - mae: 0.0055 - val_loss: 9.4102e-04 - val_mae: 0.0075\n",
            "Epoch 84/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.5746e-04 - mae: 0.0051 - val_loss: 8.1166e-04 - val_mae: 0.0075\n",
            "Epoch 85/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.1008e-04 - mae: 0.0051 - val_loss: 0.0016 - val_mae: 0.0071\n",
            "Epoch 86/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.6239e-04 - mae: 0.0047 - val_loss: 9.2759e-04 - val_mae: 0.0069\n",
            "Epoch 87/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.7007e-04 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0068\n",
            "Epoch 88/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.1541e-04 - mae: 0.0043 - val_loss: 6.3690e-04 - val_mae: 0.0070\n",
            "Epoch 89/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.6756e-04 - mae: 0.0047 - val_loss: 6.9377e-04 - val_mae: 0.0066\n",
            "Epoch 90/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.4831e-04 - mae: 0.0045 - val_loss: 8.6896e-04 - val_mae: 0.0063\n",
            "Epoch 91/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.1089e-04 - mae: 0.0038 - val_loss: 6.3717e-04 - val_mae: 0.0064\n",
            "Epoch 92/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.5531e-04 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0064\n",
            "Epoch 93/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6436e-04 - mae: 0.0034 - val_loss: 4.9144e-04 - val_mae: 0.0066\n",
            "Epoch 94/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.3716e-04 - mae: 0.0041 - val_loss: 7.0817e-04 - val_mae: 0.0057\n",
            "Epoch 95/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.8157e-04 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0055\n",
            "Epoch 96/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.8913e-04 - mae: 0.0031 - val_loss: 4.4470e-04 - val_mae: 0.0061\n",
            "Epoch 97/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9872e-04 - mae: 0.0039 - val_loss: 4.8744e-04 - val_mae: 0.0057\n",
            "Epoch 98/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.7645e-04 - mae: 0.0036 - val_loss: 7.6792e-04 - val_mae: 0.0052\n",
            "Epoch 99/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.5890e-04 - mae: 0.0035 - val_loss: 8.0938e-04 - val_mae: 0.0051\n",
            "Epoch 100/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.7222e-04 - mae: 0.0032 - val_loss: 0.0016 - val_mae: 0.0055\n",
            "Epoch 101/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.5365e-04 - mae: 0.0031 - val_loss: 5.7521e-04 - val_mae: 0.0050\n",
            "Epoch 102/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.5546e-04 - mae: 0.0030 - val_loss: 4.0989e-04 - val_mae: 0.0053\n",
            "Epoch 103/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9045e-04 - mae: 0.0031 - val_loss: 4.4400e-04 - val_mae: 0.0050\n",
            "Epoch 104/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.2348e-04 - mae: 0.0035 - val_loss: 4.6240e-04 - val_mae: 0.0048\n",
            "Epoch 105/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.8522e-04 - mae: 0.0031 - val_loss: 6.1910e-04 - val_mae: 0.0046\n",
            "Epoch 106/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6143e-04 - mae: 0.0029 - val_loss: 5.2481e-04 - val_mae: 0.0045\n",
            "Epoch 107/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.1314e-04 - mae: 0.0031 - val_loss: 0.0012 - val_mae: 0.0047\n",
            "Epoch 108/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9206e-04 - mae: 0.0027 - val_loss: 5.3419e-04 - val_mae: 0.0044\n",
            "Epoch 109/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.7509e-04 - mae: 0.0028 - val_loss: 8.4720e-04 - val_mae: 0.0043\n",
            "Epoch 110/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.3647e-04 - mae: 0.0023 - val_loss: 3.7551e-04 - val_mae: 0.0043\n",
            "Epoch 111/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.9820e-05 - mae: 0.0028 - val_loss: 6.9337e-04 - val_mae: 0.0041\n",
            "Epoch 112/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.4516e-04 - mae: 0.0026 - val_loss: 4.9591e-04 - val_mae: 0.0040\n",
            "Epoch 113/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.0582e-05 - mae: 0.0023 - val_loss: 2.7299e-04 - val_mae: 0.0044\n",
            "Epoch 114/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.3872e-05 - mae: 0.0023 - val_loss: 9.3503e-04 - val_mae: 0.0041\n",
            "Epoch 115/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.4132e-04 - mae: 0.0024 - val_loss: 5.3964e-04 - val_mae: 0.0038\n",
            "Epoch 116/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.3992e-05 - mae: 0.0024 - val_loss: 9.9423e-04 - val_mae: 0.0041\n",
            "Epoch 117/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9387e-04 - mae: 0.0022 - val_loss: 4.4999e-04 - val_mae: 0.0037\n",
            "Epoch 118/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.6711e-05 - mae: 0.0024 - val_loss: 5.8025e-04 - val_mae: 0.0036\n",
            "Epoch 119/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3143e-04 - mae: 0.0021 - val_loss: 3.9335e-04 - val_mae: 0.0035\n",
            "Epoch 120/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.4718e-04 - mae: 0.0021 - val_loss: 4.0845e-04 - val_mae: 0.0035\n",
            "Epoch 121/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2066e-04 - mae: 0.0020 - val_loss: 2.9311e-04 - val_mae: 0.0035\n",
            "Epoch 122/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.4427e-05 - mae: 0.0022 - val_loss: 3.6192e-04 - val_mae: 0.0033\n",
            "Epoch 123/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 9.5302e-05 - mae: 0.0021 - val_loss: 3.8015e-04 - val_mae: 0.0033\n",
            "Epoch 124/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.4831e-05 - mae: 0.0021 - val_loss: 4.7930e-04 - val_mae: 0.0033\n",
            "Epoch 125/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.5596e-04 - mae: 0.0019 - val_loss: 4.3641e-04 - val_mae: 0.0032\n",
            "Epoch 126/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.5253e-05 - mae: 0.0017 - val_loss: 2.2481e-04 - val_mae: 0.0032\n",
            "Epoch 127/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.5767e-05 - mae: 0.0020 - val_loss: 2.0905e-04 - val_mae: 0.0032\n",
            "Epoch 128/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.8351e-05 - mae: 0.0019 - val_loss: 2.2083e-04 - val_mae: 0.0030\n",
            "Epoch 129/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.1815e-05 - mae: 0.0017 - val_loss: 9.7721e-04 - val_mae: 0.0036\n",
            "Epoch 130/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.1333e-05 - mae: 0.0016 - val_loss: 3.3246e-04 - val_mae: 0.0029\n",
            "Epoch 131/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.3491e-04 - mae: 0.0017 - val_loss: 5.3613e-04 - val_mae: 0.0029\n",
            "Epoch 132/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.4734e-05 - mae: 0.0015 - val_loss: 5.3096e-04 - val_mae: 0.0029\n",
            "Epoch 133/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.3994e-05 - mae: 0.0013 - val_loss: 1.4485e-04 - val_mae: 0.0029\n",
            "Epoch 134/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.6823e-05 - mae: 0.0016 - val_loss: 2.3991e-04 - val_mae: 0.0026\n",
            "Epoch 135/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.0716e-05 - mae: 0.0014 - val_loss: 2.1967e-04 - val_mae: 0.0026\n",
            "Epoch 136/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.2526e-05 - mae: 0.0015 - val_loss: 2.8237e-04 - val_mae: 0.0025\n",
            "Epoch 137/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.7422e-05 - mae: 0.0014 - val_loss: 2.0319e-04 - val_mae: 0.0025\n",
            "Epoch 138/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.8200e-05 - mae: 0.0015 - val_loss: 2.0734e-04 - val_mae: 0.0025\n",
            "Epoch 139/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 8.6393e-05 - mae: 0.0014 - val_loss: 2.7184e-04 - val_mae: 0.0024\n",
            "Epoch 140/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.2546e-05 - mae: 0.0014 - val_loss: 3.3273e-04 - val_mae: 0.0025\n",
            "Epoch 141/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.9223e-05 - mae: 0.0013 - val_loss: 8.8712e-04 - val_mae: 0.0031\n",
            "Epoch 142/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3028e-04 - mae: 0.0013 - val_loss: 3.9321e-04 - val_mae: 0.0025\n",
            "Epoch 143/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.6555e-05 - mae: 0.0012 - val_loss: 1.9476e-04 - val_mae: 0.0023\n",
            "Epoch 144/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.2254e-05 - mae: 0.0012 - val_loss: 2.5732e-04 - val_mae: 0.0023\n",
            "Epoch 145/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 5.6945e-05 - mae: 0.0013 - val_loss: 2.4509e-04 - val_mae: 0.0022\n",
            "Epoch 146/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.6153e-05 - mae: 0.0013 - val_loss: 4.2478e-04 - val_mae: 0.0024\n",
            "Epoch 147/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.2308e-05 - mae: 0.0011 - val_loss: 1.4076e-04 - val_mae: 0.0022\n",
            "Epoch 148/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.3353e-05 - mae: 0.0013 - val_loss: 2.6237e-04 - val_mae: 0.0022\n",
            "Epoch 149/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 6.0134e-05 - mae: 0.0012 - val_loss: 1.4927e-04 - val_mae: 0.0021\n",
            "Epoch 150/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.4425e-05 - mae: 0.0011 - val_loss: 2.5583e-04 - val_mae: 0.0021\n",
            "Epoch 151/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.3537e-05 - mae: 0.0011 - val_loss: 1.8860e-04 - val_mae: 0.0020\n",
            "Epoch 152/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.4387e-05 - mae: 0.0010 - val_loss: 1.5289e-04 - val_mae: 0.0020\n",
            "Epoch 153/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.5084e-05 - mae: 0.0011 - val_loss: 1.7068e-04 - val_mae: 0.0020\n",
            "Epoch 154/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.3608e-05 - mae: 0.0011 - val_loss: 2.0497e-04 - val_mae: 0.0020\n",
            "Epoch 155/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.0929e-05 - mae: 0.0011 - val_loss: 3.6917e-04 - val_mae: 0.0022\n",
            "Epoch 156/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.1329e-05 - mae: 9.6726e-04 - val_loss: 1.3278e-04 - val_mae: 0.0019\n",
            "Epoch 157/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.2545e-05 - mae: 0.0011 - val_loss: 1.4107e-04 - val_mae: 0.0018\n",
            "Epoch 158/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.1272e-05 - mae: 0.0010 - val_loss: 3.5643e-04 - val_mae: 0.0021\n",
            "Epoch 159/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.1609e-04 - mae: 9.7476e-04 - val_loss: 2.7985e-04 - val_mae: 0.0020\n",
            "Epoch 160/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.6720e-05 - mae: 8.8769e-04 - val_loss: 1.0173e-04 - val_mae: 0.0018\n",
            "Epoch 161/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.6658e-05 - mae: 9.3713e-04 - val_loss: 2.3114e-04 - val_mae: 0.0019\n",
            "Epoch 162/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.4560e-05 - mae: 9.2008e-04 - val_loss: 1.1848e-04 - val_mae: 0.0017\n",
            "Epoch 163/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.7946e-05 - mae: 9.4061e-04 - val_loss: 1.8229e-04 - val_mae: 0.0017\n",
            "Epoch 164/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.8946e-05 - mae: 8.9921e-04 - val_loss: 2.6965e-04 - val_mae: 0.0019\n",
            "Epoch 165/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.6485e-05 - mae: 8.2661e-04 - val_loss: 3.4517e-04 - val_mae: 0.0020\n",
            "Epoch 166/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.0826e-05 - mae: 8.5963e-04 - val_loss: 1.2468e-04 - val_mae: 0.0016\n",
            "Epoch 167/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.4600e-05 - mae: 8.2978e-04 - val_loss: 8.7010e-05 - val_mae: 0.0016\n",
            "Epoch 168/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.2492e-05 - mae: 8.7306e-04 - val_loss: 2.5033e-04 - val_mae: 0.0018\n",
            "Epoch 169/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.3187e-05 - mae: 7.7378e-04 - val_loss: 1.4284e-04 - val_mae: 0.0016\n",
            "Epoch 170/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.7728e-05 - mae: 8.0472e-04 - val_loss: 1.5528e-04 - val_mae: 0.0016\n",
            "Epoch 171/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.4625e-05 - mae: 8.2559e-04 - val_loss: 2.5406e-04 - val_mae: 0.0017\n",
            "Epoch 172/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.4138e-05 - mae: 7.6830e-04 - val_loss: 8.7054e-05 - val_mae: 0.0015\n",
            "Epoch 173/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.8625e-05 - mae: 7.6895e-04 - val_loss: 1.1378e-04 - val_mae: 0.0015\n",
            "Epoch 174/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2410e-05 - mae: 6.6424e-04 - val_loss: 5.1555e-05 - val_mae: 0.0016\n",
            "Epoch 175/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.6426e-06 - mae: 7.8470e-04 - val_loss: 1.9279e-04 - val_mae: 0.0016\n",
            "Epoch 176/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9302e-05 - mae: 7.3901e-04 - val_loss: 9.4894e-05 - val_mae: 0.0014\n",
            "Epoch 177/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.2158e-05 - mae: 7.2116e-04 - val_loss: 1.1396e-04 - val_mae: 0.0014\n",
            "Epoch 178/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.0059e-05 - mae: 6.0830e-04 - val_loss: 4.5822e-05 - val_mae: 0.0015\n",
            "Epoch 179/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.4076e-06 - mae: 7.4636e-04 - val_loss: 3.1989e-04 - val_mae: 0.0018\n",
            "Epoch 180/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.4993e-05 - mae: 6.4150e-04 - val_loss: 8.0820e-05 - val_mae: 0.0013\n",
            "Epoch 181/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.5262e-05 - mae: 6.3370e-04 - val_loss: 7.0448e-05 - val_mae: 0.0013\n",
            "Epoch 182/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.0900e-05 - mae: 6.9375e-04 - val_loss: 9.6884e-05 - val_mae: 0.0013\n",
            "Epoch 183/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.4345e-05 - mae: 6.5896e-04 - val_loss: 1.5472e-04 - val_mae: 0.0014\n",
            "Epoch 184/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.2044e-05 - mae: 5.9290e-04 - val_loss: 6.6757e-05 - val_mae: 0.0012\n",
            "Epoch 185/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.0870e-05 - mae: 6.3060e-04 - val_loss: 9.0673e-05 - val_mae: 0.0012\n",
            "Epoch 186/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.5367e-06 - mae: 5.8997e-04 - val_loss: 5.6580e-05 - val_mae: 0.0012\n",
            "Epoch 187/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.4797e-06 - mae: 5.8268e-04 - val_loss: 2.6896e-04 - val_mae: 0.0016\n",
            "Epoch 188/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.3894e-05 - mae: 5.6066e-04 - val_loss: 1.1788e-04 - val_mae: 0.0013\n",
            "Epoch 189/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.9711e-05 - mae: 5.8782e-04 - val_loss: 1.6376e-04 - val_mae: 0.0014\n",
            "Epoch 190/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.1842e-06 - mae: 4.9189e-04 - val_loss: 3.9730e-05 - val_mae: 0.0012\n",
            "Epoch 191/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.0714e-06 - mae: 5.4950e-04 - val_loss: 2.6218e-04 - val_mae: 0.0016\n",
            "Epoch 192/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9477e-05 - mae: 5.2750e-04 - val_loss: 2.4728e-04 - val_mae: 0.0015\n",
            "Epoch 193/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.9803e-05 - mae: 5.6118e-04 - val_loss: 7.0642e-05 - val_mae: 0.0011\n",
            "Epoch 194/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.8275e-05 - mae: 5.2681e-04 - val_loss: 1.0997e-04 - val_mae: 0.0012\n",
            "Epoch 195/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.7319e-06 - mae: 5.2918e-04 - val_loss: 5.0127e-05 - val_mae: 0.0011\n",
            "Epoch 196/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.7506e-06 - mae: 5.0685e-04 - val_loss: 1.8051e-04 - val_mae: 0.0013\n",
            "Epoch 197/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.8870e-05 - mae: 5.9910e-04 - val_loss: 1.1312e-04 - val_mae: 0.0012\n",
            "Epoch 198/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.6254e-06 - mae: 5.0781e-04 - val_loss: 1.3981e-04 - val_mae: 0.0012\n",
            "Epoch 199/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.1590e-05 - mae: 5.9382e-04 - val_loss: 1.8330e-04 - val_mae: 0.0013\n",
            "Epoch 200/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.0821e-05 - mae: 4.6004e-04 - val_loss: 1.8165e-04 - val_mae: 0.0013\n",
            "Epoch 201/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.7296e-05 - mae: 5.0842e-04 - val_loss: 7.4622e-05 - val_mae: 0.0011\n",
            "Epoch 202/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.3327e-06 - mae: 4.2003e-04 - val_loss: 3.2752e-05 - val_mae: 0.0010\n",
            "Epoch 203/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.1886e-06 - mae: 5.2757e-04 - val_loss: 5.3655e-05 - val_mae: 9.8072e-04\n",
            "Epoch 204/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.4221e-06 - mae: 4.7936e-04 - val_loss: 1.7826e-04 - val_mae: 0.0013\n",
            "Epoch 205/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.5708e-06 - mae: 4.2921e-04 - val_loss: 9.3062e-05 - val_mae: 0.0010\n",
            "Epoch 206/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6271e-05 - mae: 4.4574e-04 - val_loss: 7.9048e-05 - val_mae: 0.0010\n",
            "Epoch 207/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6639e-05 - mae: 4.5110e-04 - val_loss: 8.8222e-05 - val_mae: 0.0010\n",
            "Epoch 208/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.7808e-06 - mae: 4.3030e-04 - val_loss: 4.2171e-05 - val_mae: 8.9732e-04\n",
            "Epoch 209/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.3151e-06 - mae: 4.1167e-04 - val_loss: 4.4317e-05 - val_mae: 8.9221e-04\n",
            "Epoch 210/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.4807e-06 - mae: 3.9359e-04 - val_loss: 1.3732e-04 - val_mae: 0.0011\n",
            "Epoch 211/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.0899e-05 - mae: 5.1452e-04 - val_loss: 2.4013e-04 - val_mae: 0.0014\n",
            "Epoch 212/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.4924e-05 - mae: 3.9006e-04 - val_loss: 7.3519e-05 - val_mae: 9.5663e-04\n",
            "Epoch 213/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.0944e-05 - mae: 3.8189e-04 - val_loss: 6.0654e-05 - val_mae: 9.0894e-04\n",
            "Epoch 214/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.4834e-06 - mae: 3.8047e-04 - val_loss: 2.7496e-05 - val_mae: 8.4614e-04\n",
            "Epoch 215/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.8910e-06 - mae: 4.0650e-04 - val_loss: 2.7814e-05 - val_mae: 8.2334e-04\n",
            "Epoch 216/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.0338e-05 - mae: 4.3077e-04 - val_loss: 9.4831e-05 - val_mae: 9.8048e-04\n",
            "Epoch 217/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.1961e-06 - mae: 3.5760e-04 - val_loss: 3.8448e-05 - val_mae: 8.1492e-04\n",
            "Epoch 218/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.0714e-06 - mae: 3.6817e-04 - val_loss: 1.2827e-04 - val_mae: 0.0011\n",
            "Epoch 219/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.7165e-05 - mae: 4.0397e-04 - val_loss: 8.1349e-05 - val_mae: 9.8245e-04\n",
            "Epoch 220/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.0678e-06 - mae: 3.7337e-04 - val_loss: 5.2137e-05 - val_mae: 8.5718e-04\n",
            "Epoch 221/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.9849e-06 - mae: 3.5620e-04 - val_loss: 2.5823e-05 - val_mae: 7.8883e-04\n",
            "Epoch 222/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.8683e-06 - mae: 3.5491e-04 - val_loss: 4.8200e-05 - val_mae: 8.0248e-04\n",
            "Epoch 223/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.9108e-06 - mae: 3.3271e-04 - val_loss: 2.8511e-05 - val_mae: 7.4160e-04\n",
            "Epoch 224/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.5863e-06 - mae: 3.4574e-04 - val_loss: 4.8167e-05 - val_mae: 7.8385e-04\n",
            "Epoch 225/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.6489e-06 - mae: 3.4176e-04 - val_loss: 4.3889e-05 - val_mae: 7.6081e-04\n",
            "Epoch 226/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.1352e-05 - mae: 3.7579e-04 - val_loss: 1.0463e-04 - val_mae: 9.5878e-04\n",
            "Epoch 227/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.3939e-06 - mae: 3.0711e-04 - val_loss: 3.7194e-05 - val_mae: 7.3549e-04\n",
            "Epoch 228/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.9469e-06 - mae: 2.9429e-04 - val_loss: 1.5433e-04 - val_mae: 0.0011\n",
            "Epoch 229/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.2335e-06 - mae: 3.2484e-04 - val_loss: 5.2226e-05 - val_mae: 7.7083e-04\n",
            "Epoch 230/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.4228e-06 - mae: 2.9209e-04 - val_loss: 9.2555e-05 - val_mae: 9.0399e-04\n",
            "Epoch 231/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.5446e-06 - mae: 3.0714e-04 - val_loss: 2.9930e-05 - val_mae: 6.8280e-04\n",
            "Epoch 232/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.5375e-06 - mae: 2.9092e-04 - val_loss: 2.6764e-05 - val_mae: 6.7088e-04\n",
            "Epoch 233/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.0145e-06 - mae: 2.8346e-04 - val_loss: 4.1631e-05 - val_mae: 7.1134e-04\n",
            "Epoch 234/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.3629e-06 - mae: 2.8420e-04 - val_loss: 3.5923e-05 - val_mae: 6.8317e-04\n",
            "Epoch 235/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 6.5808e-06 - mae: 2.8001e-04 - val_loss: 5.1037e-05 - val_mae: 7.3358e-04\n",
            "Epoch 236/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.6043e-06 - mae: 2.5213e-04 - val_loss: 1.4515e-05 - val_mae: 6.2567e-04\n",
            "Epoch 237/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.4634e-06 - mae: 3.1304e-04 - val_loss: 5.6930e-05 - val_mae: 7.5015e-04\n",
            "Epoch 238/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.3964e-06 - mae: 2.4927e-04 - val_loss: 3.5922e-05 - val_mae: 6.6544e-04\n",
            "Epoch 239/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.8877e-06 - mae: 2.7067e-04 - val_loss: 2.8360e-05 - val_mae: 6.2533e-04\n",
            "Epoch 240/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.3694e-06 - mae: 2.4299e-04 - val_loss: 1.6503e-04 - val_mae: 0.0011\n",
            "Epoch 241/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.4625e-06 - mae: 2.6810e-04 - val_loss: 6.6882e-05 - val_mae: 7.6879e-04\n",
            "Epoch 242/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.5693e-06 - mae: 2.6193e-04 - val_loss: 5.3393e-05 - val_mae: 7.1184e-04\n",
            "Epoch 243/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.6389e-06 - mae: 2.4973e-04 - val_loss: 3.5782e-05 - val_mae: 6.3529e-04\n",
            "Epoch 244/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.3010e-07 - mae: 1.9957e-04 - val_loss: 2.5839e-04 - val_mae: 0.0013\n",
            "Epoch 245/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.1634e-06 - mae: 2.2819e-04 - val_loss: 2.4894e-05 - val_mae: 5.8671e-04\n",
            "Epoch 246/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9449e-06 - mae: 2.4003e-04 - val_loss: 1.9054e-05 - val_mae: 5.5547e-04\n",
            "Epoch 247/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0600e-06 - mae: 2.2953e-04 - val_loss: 1.0034e-04 - val_mae: 8.6863e-04\n",
            "Epoch 248/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.6929e-06 - mae: 2.1648e-04 - val_loss: 2.7558e-05 - val_mae: 5.8010e-04\n",
            "Epoch 249/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.3708e-07 - mae: 1.8481e-04 - val_loss: 8.4731e-06 - val_mae: 5.4334e-04\n",
            "Epoch 250/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.9704e-06 - mae: 2.4171e-04 - val_loss: 3.1208e-05 - val_mae: 5.8215e-04\n",
            "Epoch 251/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2148e-06 - mae: 2.0970e-04 - val_loss: 4.4685e-05 - val_mae: 6.3935e-04\n",
            "Epoch 252/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6671e-06 - mae: 2.1119e-04 - val_loss: 7.7208e-05 - val_mae: 7.7043e-04\n",
            "Epoch 253/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.7278e-06 - mae: 2.0523e-04 - val_loss: 3.9555e-05 - val_mae: 6.2543e-04\n",
            "Epoch 254/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.1791e-06 - mae: 2.1056e-04 - val_loss: 3.1025e-05 - val_mae: 5.6751e-04\n",
            "Epoch 255/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.8559e-07 - mae: 1.8670e-04 - val_loss: 8.6489e-06 - val_mae: 4.8349e-04\n",
            "Epoch 256/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6140e-06 - mae: 2.0697e-04 - val_loss: 1.2981e-05 - val_mae: 4.7311e-04\n",
            "Epoch 257/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.7406e-06 - mae: 1.9529e-04 - val_loss: 1.7377e-05 - val_mae: 4.8567e-04\n",
            "Epoch 258/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 6.6310e-07 - mae: 1.7604e-04 - val_loss: 1.3844e-04 - val_mae: 9.6370e-04\n",
            "Epoch 259/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.8039e-06 - mae: 1.9328e-04 - val_loss: 2.1902e-05 - val_mae: 5.0645e-04\n",
            "Epoch 260/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.4485e-06 - mae: 1.9952e-04 - val_loss: 3.2611e-05 - val_mae: 5.5803e-04\n",
            "Epoch 261/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.1091e-06 - mae: 1.8373e-04 - val_loss: 1.6364e-05 - val_mae: 4.6451e-04\n",
            "Epoch 262/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.7126e-06 - mae: 1.8082e-04 - val_loss: 1.7086e-05 - val_mae: 4.6860e-04\n",
            "Epoch 263/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.7762e-07 - mae: 1.8169e-04 - val_loss: 1.0122e-05 - val_mae: 4.2943e-04\n",
            "Epoch 264/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.8936e-06 - mae: 1.7613e-04 - val_loss: 1.8045e-05 - val_mae: 4.6209e-04\n",
            "Epoch 265/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6367e-06 - mae: 1.6647e-04 - val_loss: 8.9581e-06 - val_mae: 4.2030e-04\n",
            "Epoch 266/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.5603e-07 - mae: 1.6742e-04 - val_loss: 1.9291e-05 - val_mae: 4.6436e-04\n",
            "Epoch 267/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1148e-06 - mae: 1.6651e-04 - val_loss: 6.8885e-06 - val_mae: 4.0634e-04\n",
            "Epoch 268/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 7.1574e-07 - mae: 1.7236e-04 - val_loss: 2.1260e-05 - val_mae: 4.6555e-04\n",
            "Epoch 269/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.3245e-06 - mae: 1.6774e-04 - val_loss: 2.6142e-05 - val_mae: 4.9293e-04\n",
            "Epoch 270/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 8.2353e-07 - mae: 1.5638e-04 - val_loss: 1.0087e-05 - val_mae: 3.9712e-04\n",
            "Epoch 271/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.4277e-06 - mae: 1.6614e-04 - val_loss: 1.9968e-05 - val_mae: 4.5109e-04\n",
            "Epoch 272/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.8422e-07 - mae: 1.4376e-04 - val_loss: 7.3983e-06 - val_mae: 3.8018e-04\n",
            "Epoch 273/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.9883e-07 - mae: 1.2894e-04 - val_loss: 1.1762e-04 - val_mae: 8.7374e-04\n",
            "Epoch 274/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6275e-06 - mae: 1.5708e-04 - val_loss: 1.1853e-05 - val_mae: 4.0097e-04\n",
            "Epoch 275/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.1999e-07 - mae: 1.4007e-04 - val_loss: 8.5139e-06 - val_mae: 3.7974e-04\n",
            "Epoch 276/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.1912e-06 - mae: 1.5884e-04 - val_loss: 1.9829e-05 - val_mae: 4.3878e-04\n",
            "Epoch 277/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.6826e-07 - mae: 1.3772e-04 - val_loss: 2.2211e-05 - val_mae: 4.5010e-04\n",
            "Epoch 278/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.5897e-07 - mae: 1.4166e-04 - val_loss: 1.6054e-05 - val_mae: 4.1110e-04\n",
            "Epoch 279/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2208e-06 - mae: 1.3455e-04 - val_loss: 7.8528e-06 - val_mae: 3.5516e-04\n",
            "Epoch 280/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.5163e-07 - mae: 1.3064e-04 - val_loss: 4.0659e-06 - val_mae: 3.5817e-04\n",
            "Epoch 281/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.3885e-07 - mae: 1.4262e-04 - val_loss: 7.1481e-06 - val_mae: 3.3941e-04\n",
            "Epoch 282/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.1157e-07 - mae: 1.2289e-04 - val_loss: 5.0213e-06 - val_mae: 3.2675e-04\n",
            "Epoch 283/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.6041e-07 - mae: 1.3298e-04 - val_loss: 6.6190e-06 - val_mae: 3.2514e-04\n",
            "Epoch 284/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 6.5319e-07 - mae: 1.1259e-04 - val_loss: 6.2654e-06 - val_mae: 3.3264e-04\n",
            "Epoch 285/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.4796e-07 - mae: 1.2146e-04 - val_loss: 1.0208e-05 - val_mae: 3.4742e-04\n",
            "Epoch 286/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 9.6989e-07 - mae: 1.1866e-04 - val_loss: 5.9458e-06 - val_mae: 3.1437e-04\n",
            "Epoch 287/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.1289e-07 - mae: 1.2173e-04 - val_loss: 6.8611e-06 - val_mae: 3.1419e-04\n",
            "Epoch 288/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1412e-06 - mae: 1.2634e-04 - val_loss: 1.1159e-05 - val_mae: 3.4401e-04\n",
            "Epoch 289/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.6540e-07 - mae: 1.0130e-04 - val_loss: 4.3526e-05 - val_mae: 5.4761e-04\n",
            "Epoch 290/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.0314e-06 - mae: 1.2363e-04 - val_loss: 1.3104e-05 - val_mae: 3.5962e-04\n",
            "Epoch 291/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.0400e-07 - mae: 1.1383e-04 - val_loss: 1.6622e-05 - val_mae: 3.8032e-04\n",
            "Epoch 292/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.5643e-07 - mae: 1.1282e-04 - val_loss: 7.7743e-06 - val_mae: 3.0703e-04\n",
            "Epoch 293/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.8316e-07 - mae: 1.0773e-04 - val_loss: 7.8460e-06 - val_mae: 3.0452e-04\n",
            "Epoch 294/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.1495e-07 - mae: 1.0184e-04 - val_loss: 2.4573e-05 - val_mae: 4.2951e-04\n",
            "Epoch 295/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.6396e-07 - mae: 9.2557e-05 - val_loss: 4.2188e-06 - val_mae: 2.8424e-04\n",
            "Epoch 296/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.8965e-07 - mae: 9.8685e-05 - val_loss: 4.0553e-05 - val_mae: 5.2024e-04\n",
            "Epoch 297/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.7206e-07 - mae: 9.7379e-05 - val_loss: 6.6046e-06 - val_mae: 2.9544e-04\n",
            "Epoch 298/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.4769e-07 - mae: 9.7663e-05 - val_loss: 6.7289e-06 - val_mae: 2.9160e-04\n",
            "Epoch 299/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.3072e-07 - mae: 9.9250e-05 - val_loss: 1.8503e-05 - val_mae: 3.7940e-04\n",
            "Epoch 300/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 7.3371e-07 - mae: 9.9189e-05 - val_loss: 6.0750e-06 - val_mae: 2.7408e-04\n",
            "Epoch 301/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 5.1239e-07 - mae: 9.3260e-05 - val_loss: 1.0205e-05 - val_mae: 3.0829e-04\n",
            "Epoch 302/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.4541e-07 - mae: 9.0585e-05 - val_loss: 1.2406e-05 - val_mae: 3.2550e-04\n",
            "Epoch 303/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.8834e-07 - mae: 9.5655e-05 - val_loss: 5.9686e-06 - val_mae: 2.6956e-04\n",
            "Epoch 304/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.1610e-07 - mae: 9.2027e-05 - val_loss: 5.5211e-06 - val_mae: 2.6018e-04\n",
            "Epoch 305/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 5.0254e-07 - mae: 8.7921e-05 - val_loss: 8.0514e-06 - val_mae: 2.8298e-04\n",
            "Epoch 306/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.2628e-07 - mae: 9.0731e-05 - val_loss: 5.1259e-06 - val_mae: 2.5312e-04\n",
            "Epoch 307/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.8124e-07 - mae: 8.3048e-05 - val_loss: 4.6090e-06 - val_mae: 2.4340e-04\n",
            "Epoch 308/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1293e-07 - mae: 7.9580e-05 - val_loss: 1.6816e-05 - val_mae: 3.5377e-04\n",
            "Epoch 309/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.6289e-07 - mae: 8.4001e-05 - val_loss: 1.9004e-05 - val_mae: 3.7063e-04\n",
            "Epoch 310/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.7960e-07 - mae: 8.0860e-05 - val_loss: 2.7934e-05 - val_mae: 4.3134e-04\n",
            "Epoch 311/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.6469e-07 - mae: 8.2418e-05 - val_loss: 5.4462e-06 - val_mae: 2.4425e-04\n",
            "Epoch 312/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.3318e-07 - mae: 7.2519e-05 - val_loss: 2.5651e-05 - val_mae: 4.1504e-04\n",
            "Epoch 313/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.2092e-07 - mae: 8.0984e-05 - val_loss: 1.6646e-05 - val_mae: 3.4720e-04\n",
            "Epoch 314/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.9231e-07 - mae: 8.5898e-05 - val_loss: 8.3633e-06 - val_mae: 2.7069e-04\n",
            "Epoch 315/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6170e-07 - mae: 7.3850e-05 - val_loss: 5.0906e-06 - val_mae: 2.3397e-04\n",
            "Epoch 316/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.6769e-07 - mae: 7.5913e-05 - val_loss: 4.1547e-06 - val_mae: 2.2203e-04\n",
            "Epoch 317/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.8673e-07 - mae: 7.6737e-05 - val_loss: 2.7004e-06 - val_mae: 2.0596e-04\n",
            "Epoch 318/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 9.2782e-08 - mae: 7.0491e-05 - val_loss: 1.5338e-05 - val_mae: 3.3059e-04\n",
            "Epoch 319/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 5.8389e-07 - mae: 7.5130e-05 - val_loss: 8.2835e-06 - val_mae: 2.6434e-04\n",
            "Epoch 320/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.0747e-07 - mae: 6.7389e-05 - val_loss: 7.5273e-06 - val_mae: 2.5534e-04\n",
            "Epoch 321/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.5028e-07 - mae: 7.1288e-05 - val_loss: 7.1065e-06 - val_mae: 2.4894e-04\n",
            "Epoch 322/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.3203e-07 - mae: 7.2487e-05 - val_loss: 5.6500e-06 - val_mae: 2.3621e-04\n",
            "Epoch 323/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0860e-07 - mae: 6.0122e-05 - val_loss: 1.6513e-06 - val_mae: 1.8969e-04\n",
            "Epoch 324/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9601e-07 - mae: 6.5846e-05 - val_loss: 2.6589e-06 - val_mae: 1.9586e-04\n",
            "Epoch 325/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.3178e-07 - mae: 6.7696e-05 - val_loss: 3.9626e-06 - val_mae: 2.0851e-04\n",
            "Epoch 326/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.1213e-07 - mae: 6.6407e-05 - val_loss: 2.9259e-06 - val_mae: 1.9165e-04\n",
            "Epoch 327/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.0761e-07 - mae: 6.4284e-05 - val_loss: 3.0039e-06 - val_mae: 1.9151e-04\n",
            "Epoch 328/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.0813e-07 - mae: 7.2037e-05 - val_loss: 6.0866e-06 - val_mae: 2.2853e-04\n",
            "Epoch 329/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.5494e-08 - mae: 5.2977e-05 - val_loss: 1.3536e-05 - val_mae: 3.0588e-04\n",
            "Epoch 330/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.4268e-07 - mae: 6.1331e-05 - val_loss: 2.0500e-05 - val_mae: 3.6289e-04\n",
            "Epoch 331/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.5052e-07 - mae: 6.0986e-05 - val_loss: 4.7845e-06 - val_mae: 2.1096e-04\n",
            "Epoch 332/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1801e-07 - mae: 6.0869e-05 - val_loss: 2.1762e-06 - val_mae: 1.7607e-04\n",
            "Epoch 333/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.9268e-08 - mae: 5.6443e-05 - val_loss: 7.5831e-06 - val_mae: 2.4203e-04\n",
            "Epoch 334/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.3141e-07 - mae: 5.8546e-05 - val_loss: 2.7058e-06 - val_mae: 1.7762e-04\n",
            "Epoch 335/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.0296e-08 - mae: 5.5701e-05 - val_loss: 6.5684e-06 - val_mae: 2.2803e-04\n",
            "Epoch 336/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6776e-07 - mae: 5.9042e-05 - val_loss: 2.4107e-06 - val_mae: 1.7488e-04\n",
            "Epoch 337/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.9705e-08 - mae: 5.1856e-05 - val_loss: 7.7506e-06 - val_mae: 2.4107e-04\n",
            "Epoch 338/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.1884e-07 - mae: 5.5057e-05 - val_loss: 1.6421e-06 - val_mae: 1.6106e-04\n",
            "Epoch 339/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.9659e-08 - mae: 5.0496e-05 - val_loss: 1.3269e-06 - val_mae: 1.5831e-04\n",
            "Epoch 340/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.2591e-08 - mae: 5.4587e-05 - val_loss: 6.5293e-06 - val_mae: 2.2351e-04\n",
            "Epoch 341/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.5793e-07 - mae: 5.3236e-05 - val_loss: 4.1852e-06 - val_mae: 1.9329e-04\n",
            "Epoch 342/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.5192e-07 - mae: 5.0955e-05 - val_loss: 2.7291e-06 - val_mae: 1.7019e-04\n",
            "Epoch 343/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.3833e-07 - mae: 5.0458e-05 - val_loss: 2.1266e-06 - val_mae: 1.6003e-04\n",
            "Epoch 344/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.8178e-08 - mae: 4.6623e-05 - val_loss: 1.8468e-06 - val_mae: 1.5382e-04\n",
            "Epoch 345/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4140e-07 - mae: 5.0230e-05 - val_loss: 2.3060e-06 - val_mae: 1.6165e-04\n",
            "Epoch 346/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.2453e-08 - mae: 4.5384e-05 - val_loss: 7.2933e-06 - val_mae: 2.2963e-04\n",
            "Epoch 347/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.0472e-07 - mae: 5.2021e-05 - val_loss: 2.8936e-06 - val_mae: 1.6877e-04\n",
            "Epoch 348/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.1414e-08 - mae: 4.2563e-05 - val_loss: 2.2276e-06 - val_mae: 1.5624e-04\n",
            "Epoch 349/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 8.9207e-08 - mae: 4.4508e-05 - val_loss: 1.2926e-06 - val_mae: 1.4300e-04\n",
            "Epoch 350/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.1439e-08 - mae: 4.5001e-05 - val_loss: 3.2252e-06 - val_mae: 1.7182e-04\n",
            "Epoch 351/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 5.3093e-08 - mae: 4.3990e-05 - val_loss: 5.9532e-06 - val_mae: 2.0888e-04\n",
            "Epoch 352/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.8602e-08 - mae: 4.3570e-05 - val_loss: 9.2199e-06 - val_mae: 2.4788e-04\n",
            "Epoch 353/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.9161e-07 - mae: 4.5085e-05 - val_loss: 3.2079e-06 - val_mae: 1.7191e-04\n",
            "Epoch 354/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.0288e-08 - mae: 4.1033e-05 - val_loss: 1.3294e-06 - val_mae: 1.3541e-04\n",
            "Epoch 355/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 5.0797e-08 - mae: 4.4014e-05 - val_loss: 3.4646e-06 - val_mae: 1.6992e-04\n",
            "Epoch 356/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.5757e-08 - mae: 4.1453e-05 - val_loss: 6.5294e-06 - val_mae: 2.1383e-04\n",
            "Epoch 357/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 6.4003e-08 - mae: 4.0188e-05 - val_loss: 1.7652e-06 - val_mae: 1.4016e-04\n",
            "Epoch 358/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.2123e-07 - mae: 4.1027e-05 - val_loss: 2.1298e-06 - val_mae: 1.4473e-04\n",
            "Epoch 359/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.3908e-08 - mae: 3.9319e-05 - val_loss: 3.2522e-06 - val_mae: 1.6412e-04\n",
            "Epoch 360/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.6462e-08 - mae: 3.9328e-05 - val_loss: 3.6689e-06 - val_mae: 1.7040e-04\n",
            "Epoch 361/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.8905e-08 - mae: 3.5028e-05 - val_loss: 1.0171e-05 - val_mae: 2.5432e-04\n",
            "Epoch 362/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0078e-07 - mae: 3.9877e-05 - val_loss: 4.2140e-06 - val_mae: 1.7851e-04\n",
            "Epoch 363/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.3680e-08 - mae: 3.9702e-05 - val_loss: 1.4359e-06 - val_mae: 1.2955e-04\n",
            "Epoch 364/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.3812e-08 - mae: 3.6779e-05 - val_loss: 1.7071e-06 - val_mae: 1.3323e-04\n",
            "Epoch 365/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.8806e-08 - mae: 3.6655e-05 - val_loss: 3.6552e-06 - val_mae: 1.6748e-04\n",
            "Epoch 366/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.9131e-08 - mae: 3.7530e-05 - val_loss: 2.9603e-06 - val_mae: 1.5503e-04\n",
            "Epoch 367/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.2691e-08 - mae: 3.6921e-05 - val_loss: 1.2119e-06 - val_mae: 1.2067e-04\n",
            "Epoch 368/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.0552e-08 - mae: 3.0886e-05 - val_loss: 1.2162e-05 - val_mae: 2.7264e-04\n",
            "Epoch 369/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 5.3948e-08 - mae: 3.8711e-05 - val_loss: 1.7062e-06 - val_mae: 1.2954e-04\n",
            "Epoch 370/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.9699e-08 - mae: 3.5023e-05 - val_loss: 3.2814e-06 - val_mae: 1.5826e-04\n",
            "Epoch 371/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 7.5879e-08 - mae: 3.3633e-05 - val_loss: 1.2637e-06 - val_mae: 1.2081e-04\n",
            "Epoch 372/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.1935e-08 - mae: 3.2958e-05 - val_loss: 5.8214e-06 - val_mae: 1.9792e-04\n",
            "Epoch 373/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 6.4814e-08 - mae: 3.4563e-05 - val_loss: 1.3331e-06 - val_mae: 1.2140e-04\n",
            "Epoch 374/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.7474e-08 - mae: 3.1394e-05 - val_loss: 3.6684e-06 - val_mae: 1.6316e-04\n",
            "Epoch 375/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.7260e-08 - mae: 3.4592e-05 - val_loss: 1.3476e-06 - val_mae: 1.1879e-04\n",
            "Epoch 376/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4504e-08 - mae: 2.8237e-05 - val_loss: 7.2786e-06 - val_mae: 2.1485e-04\n",
            "Epoch 377/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.7873e-08 - mae: 3.2521e-05 - val_loss: 2.1046e-06 - val_mae: 1.3455e-04\n",
            "Epoch 378/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.9577e-08 - mae: 3.1758e-05 - val_loss: 1.5299e-06 - val_mae: 1.2113e-04\n",
            "Epoch 379/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.2051e-08 - mae: 3.0013e-05 - val_loss: 1.1792e-06 - val_mae: 1.1211e-04\n",
            "Epoch 380/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.9208e-08 - mae: 3.2007e-05 - val_loss: 1.0607e-06 - val_mae: 1.0888e-04\n",
            "Epoch 381/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.2791e-08 - mae: 2.6140e-05 - val_loss: 4.6833e-06 - val_mae: 1.7730e-04\n",
            "Epoch 382/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.1959e-08 - mae: 2.9785e-05 - val_loss: 6.2718e-07 - val_mae: 9.9640e-05\n",
            "Epoch 383/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.9515e-08 - mae: 2.9687e-05 - val_loss: 8.7661e-07 - val_mae: 1.0302e-04\n",
            "Epoch 384/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.4898e-08 - mae: 2.7332e-05 - val_loss: 3.3145e-06 - val_mae: 1.5360e-04\n",
            "Epoch 385/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.7949e-08 - mae: 2.9083e-05 - val_loss: 2.5211e-06 - val_mae: 1.3871e-04\n",
            "Epoch 386/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.1074e-08 - mae: 3.0966e-05 - val_loss: 8.1162e-07 - val_mae: 9.9813e-05\n",
            "Epoch 387/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.7729e-08 - mae: 3.0079e-05 - val_loss: 1.6282e-06 - val_mae: 1.1852e-04\n",
            "Epoch 388/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.6313e-08 - mae: 2.9008e-05 - val_loss: 1.2938e-06 - val_mae: 1.1022e-04\n",
            "Epoch 389/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.5749e-08 - mae: 2.6708e-05 - val_loss: 8.7030e-07 - val_mae: 1.0125e-04\n",
            "Epoch 390/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4824e-08 - mae: 2.6059e-05 - val_loss: 3.5035e-06 - val_mae: 1.5524e-04\n",
            "Epoch 391/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.8038e-08 - mae: 2.7314e-05 - val_loss: 4.2828e-07 - val_mae: 8.8815e-05\n",
            "Epoch 392/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.6736e-08 - mae: 2.8289e-05 - val_loss: 4.4891e-07 - val_mae: 8.6970e-05\n",
            "Epoch 393/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.7496e-08 - mae: 2.7534e-05 - val_loss: 5.6705e-07 - val_mae: 8.8561e-05\n",
            "Epoch 394/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.6644e-09 - mae: 2.4756e-05 - val_loss: 4.4680e-06 - val_mae: 1.7011e-04\n",
            "Epoch 395/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3.2493e-08 - mae: 2.7683e-05 - val_loss: 8.7671e-07 - val_mae: 9.6018e-05\n",
            "Epoch 396/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.4011e-08 - mae: 2.6406e-05 - val_loss: 6.4938e-07 - val_mae: 8.9974e-05\n",
            "Epoch 397/400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.0769e-08 - mae: 2.6434e-05 - val_loss: 1.0557e-06 - val_mae: 9.9715e-05\n",
            "Epoch 398/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.3088e-09 - mae: 2.1671e-05 - val_loss: 2.9740e-06 - val_mae: 1.4371e-04\n",
            "Epoch 399/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.4364e-08 - mae: 2.5956e-05 - val_loss: 4.4279e-07 - val_mae: 8.3351e-05\n",
            "Epoch 400/400\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.8724e-09 - mae: 2.0686e-05 - val_loss: 6.7142e-06 - val_mae: 2.0175e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Run with Test Data\n",
        "Put our test data into the model and plot the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Y0CCWJz2EK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d58da3c1-f09d-4351-87fc-dff94f7a3728"
      },
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n",
            "predictions =\n",
            " [[0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.983 0.    0.017]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.994 0.    0.006]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]]\n",
            "actual =\n",
            " [[0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95733e3-e782-4a04-db7e-7e8443f7c0bb"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "  \n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 2416 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Encode the Model in an Arduino Header File \n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d987a57c-a9a6-4ed8-9a2f-32c03a5e63e3"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header file, model.h, is 14,934 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Realtime Classification of Sensor Data on Arduino\n",
        "\n",
        "Now it's time to switch back to the tutorial instructions and run our new model on the [Arduino Nano 33 BLE Sense](https://www.arduino.cc/en/Guide/NANO33BLE)"
      ]
    }
  ]
}